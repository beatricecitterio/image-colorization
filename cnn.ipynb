{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the construction and the evaluations of CNN models for colorization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from utils.dataset import CocoDataset\n",
    "from utils.plots import plot_l, plot_a, plot_b, plot_rgb, reconstruct_lab, plot_predicted_image, plot_ab\n",
    "from utils.models import BaselineCNN, save_model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(), # tensorization brings image in range [0,1] and space CxHxW\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 82783 images.\n"
     ]
    }
   ],
   "source": [
    "path_sandro = \"coco/images/train2014\"\n",
    "path_diego = \"C:/Users/diego/coco/images/train2014/train2014\"\n",
    "dataset = CocoDataset(root=path_diego, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split our dataset in train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = int(0.2 * len(dataset))\n",
    "train_size = len(dataset) - test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "train, test = random_split(dataset, [train_size, test_size], torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now build a network of 9 convolutional layers, each followed by a ReLU activation and a BatchNorm layer, with vanishing learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=5, stride=1, padding=2),  # Conv1\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.Conv2d(4, 8, kernel_size=5, stride=1, padding=2),  # Conv2\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Conv2d(8, 16, kernel_size=5, stride=1, padding=2),  # Conv3\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),  # Conv4\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),  # Conv5\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, kernel_size=5, stride=1, padding=2),  # Conv6\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2),  # Conv7\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 128, kernel_size=5, stride=1, padding=2),  # Conv8\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 128, kernel_size=5, stride=1, padding=2),  # Conv9\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(128 * 64 * 64, 2 * 64 * 64)  # Assuming the input size 64x64, adjust accordingly\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, 2, 64, 64)  # Reshape back to expected output dimensions\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "\n",
    "criterion1 = nn.MSELoss()\n",
    "criterion2 = nn.L1Loss\n",
    "criterion3 = nn.SmoothL1Loss\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for l_channels, ab_channels in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{NUM_EPOCHS}', leave=True):\n",
    "        l_channels, ab_channels = l_channels.to(device), ab_channels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(l_channels)\n",
    "        loss = criterion1(outputs, ab_channels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()  # Update the scheduler\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "\n",
    "    # Testing loop\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for l_channels, ab_channels in tqdm(test_loader, desc='Testing', leave=True):\n",
    "            l_channels, ab_channels = l_channels.to(device), ab_channels.to(device)\n",
    "            outputs = model(l_channels)\n",
    "            loss = criterion1(outputs, ab_channels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    test_losses.append(test_loss / len(test_loader))\n",
    "\n",
    "    # Print training and validation losses\n",
    "    print(f\"Epoch {epoch + 1}, Train Loss: {train_losses[-1]}, Validation Loss: {test_losses[-1]}\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mtrain_losses\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(test_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_losses' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='train')\n",
    "plt.plot(test_losses, label='test')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(linestyle = \"--\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predicted_image(model, dataset[76543])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, \"CNN_MSELoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model1 = load_model(CNN(), \"models/CNN_MSELoss.pth\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(loaded_model1.parameters()).device # check model is on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model1.eval()\n",
    "\n",
    "total_mse = 0\n",
    "total_psnr = 0\n",
    "num_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _, l_channels, _, _, ab_channels in test_loader:\n",
    "        l_channels = l_channels.to(device)\n",
    "        ab_channels = ab_channels.to(device)\n",
    "\n",
    "        ab_preds = loaded_model1(l_channels)\n",
    "\n",
    "        mse = F.mse_loss(ab_preds, ab_channels)\n",
    "        total_mse += mse.item() * ab_channels.size(0)\n",
    "\n",
    "        max_pixel_value = 1.0  # image values are between 0 and 1\n",
    "        psnr = 20 * torch.log10(max_pixel_value**2 / mse)\n",
    "        total_psnr += psnr.item() * ab_channels.size(0)\n",
    "\n",
    "        num_samples += ab_channels.size(0)\n",
    "\n",
    "avg_mse = total_mse / num_samples\n",
    "avg_psnr = total_psnr / num_samples\n",
    "\n",
    "print(f\"Average MSE: {avg_mse:.4f}\")\n",
    "print(f\"Average PSNR: {avg_psnr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for l_channels, ab_channels in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{NUM_EPOCHS}', leave=True):\n",
    "        l_channels, ab_channels = l_channels.to(device), ab_channels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(l_channels)\n",
    "        loss = criterion2(outputs, ab_channels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()  # Update the scheduler\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "\n",
    "    # Testing loop\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for l_channels, ab_channels in tqdm(test_loader, desc='Testing', leave=True):\n",
    "            l_channels, ab_channels = l_channels.to(device), ab_channels.to(device)\n",
    "            outputs = model(l_channels)\n",
    "            loss = criterion2(outputs, ab_channels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    test_losses.append(test_loss / len(test_loader))\n",
    "\n",
    "    # Print training and validation losses\n",
    "    print(f\"Epoch {epoch + 1}, Train Loss: {train_losses[-1]}, Validation Loss: {test_losses[-1]}\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='train')\n",
    "plt.plot(test_losses, label='test')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(linestyle = \"--\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predicted_image(model, dataset[76543])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, \"CNN_L1Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model2 = load_model(CNN(), \"models/L1Loss.pth\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(loaded_model2.parameters()).device # check model is on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model2.eval()\n",
    "\n",
    "total_mse = 0\n",
    "total_psnr = 0\n",
    "num_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _, l_channels, _, _, ab_channels in test_loader:\n",
    "        l_channels = l_channels.to(device)\n",
    "        ab_channels = ab_channels.to(device)\n",
    "\n",
    "        ab_preds = loaded_model2(l_channels)\n",
    "\n",
    "        mse = F.mse_loss(ab_preds, ab_channels)\n",
    "        total_mse += mse.item() * ab_channels.size(0)\n",
    "\n",
    "        max_pixel_value = 1.0  # image values are between 0 and 1\n",
    "        psnr = 20 * torch.log10(max_pixel_value**2 / mse)\n",
    "        total_psnr += psnr.item() * ab_channels.size(0)\n",
    "\n",
    "        num_samples += ab_channels.size(0)\n",
    "\n",
    "avg_mse = total_mse / num_samples\n",
    "avg_psnr = total_psnr / num_samples\n",
    "\n",
    "print(f\"Average MSE: {avg_mse:.4f}\")\n",
    "print(f\"Average PSNR: {avg_psnr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smooth L1 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for l_channels, ab_channels in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{NUM_EPOCHS}', leave=True):\n",
    "        l_channels, ab_channels = l_channels.to(device), ab_channels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(l_channels)\n",
    "        loss = criterion3(outputs, ab_channels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()  # Update the scheduler\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "\n",
    "    # Testing loop\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for l_channels, ab_channels in tqdm(test_loader, desc='Testing', leave=True):\n",
    "            l_channels, ab_channels = l_channels.to(device), ab_channels.to(device)\n",
    "            outputs = model(l_channels)\n",
    "            loss = criterion3(outputs, ab_channels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    test_losses.append(test_loss / len(test_loader))\n",
    "\n",
    "    # Print training and validation losses\n",
    "    print(f\"Epoch {epoch + 1}, Train Loss: {train_losses[-1]}, Validation Loss: {test_losses[-1]}\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='train')\n",
    "plt.plot(test_losses, label='test')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(linestyle = \"--\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predicted_image(model, dataset[76543])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, \"CNN_SmoothL1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model3 = load_model(CNN(), \"models/CNN_SmoothL1.pth\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(loaded_model3.parameters()).device # check model is on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model3.eval()\n",
    "\n",
    "total_mse = 0\n",
    "total_psnr = 0\n",
    "num_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _, l_channels, _, _, ab_channels in test_loader:\n",
    "        l_channels = l_channels.to(device)\n",
    "        ab_channels = ab_channels.to(device)\n",
    "\n",
    "        ab_preds = loaded_model3(l_channels)\n",
    "\n",
    "        mse = F.mse_loss(ab_preds, ab_channels)\n",
    "        total_mse += mse.item() * ab_channels.size(0)\n",
    "\n",
    "        max_pixel_value = 1.0  # image values are between 0 and 1\n",
    "        psnr = 20 * torch.log10(max_pixel_value**2 / mse)\n",
    "        total_psnr += psnr.item() * ab_channels.size(0)\n",
    "\n",
    "        num_samples += ab_channels.size(0)\n",
    "\n",
    "avg_mse = total_mse / num_samples\n",
    "avg_psnr = total_psnr / num_samples\n",
    "\n",
    "print(f\"Average MSE: {avg_mse:.4f}\")\n",
    "print(f\"Average PSNR: {avg_psnr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot_rgb(img[0])\n",
    "reconstruct_lab(img[1].detach().cpu(), loaded_model1(img[1].to(device)).detach().cpu())\n",
    "reconstruct_lab(img[1].detach().cpu(), loaded_model2(img[1].to(device)).detach().cpu())\n",
    "reconstruct_lab(img[1].detach().cpu(), loaded_model3(img[1].to(device)).detach().cpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Colorization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
